{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7+iB5mAJ0sxC1BKEejDdv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLGal28/Project_s/blob/main/Image_Stitching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "7KBnKzlzSGUk",
        "outputId": "bb388fad-26b0-420c-812e-2d9c73fd6f57"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b9e044f0a69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Please input two source images: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b9e044f0a69d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv1, argv2)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage_Stitching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'panorama.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b9e044f0a69d>\u001b[0m in \u001b[0;36mblending\u001b[0;34m(self, img1, img2)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mblending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mheight_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mwidth_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b9e044f0a69d>\u001b[0m in \u001b[0;36mregistration\u001b[0;34m(self, img1, img2)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregistration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mkp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBFMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/features2d/src/sift.dispatch.cpp:477: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'detectAndCompute'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "class Image_Stitching():\n",
        "    def __init__(self) :\n",
        "        self.ratio=0.85\n",
        "        self.min_match=10\n",
        "        self.sift=cv2.xfeatures2d.SIFT_create()\n",
        "        self.smoothing_window_size=800\n",
        "\n",
        "    def registration(self,img1,img2):\n",
        "        kp1, des1 = self.sift.detectAndCompute(img1, None)\n",
        "        kp2, des2 = self.sift.detectAndCompute(img2, None)\n",
        "        matcher = cv2.BFMatcher()\n",
        "        raw_matches = matcher.knnMatch(des1, des2, k=2)\n",
        "        good_points = []\n",
        "        good_matches=[]\n",
        "        for m1, m2 in raw_matches:\n",
        "            if m1.distance < self.ratio * m2.distance:\n",
        "                good_points.append((m1.trainIdx, m1.queryIdx))\n",
        "                good_matches.append([m1])\n",
        "        img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches, None, flags=2)\n",
        "        cv2.imwrite('matching.jpg', img3)\n",
        "        if len(good_points) > self.min_match:\n",
        "            image1_kp = np.float32(\n",
        "                [kp1[i].pt for (_, i) in good_points])\n",
        "            image2_kp = np.float32(\n",
        "                [kp2[i].pt for (i, _) in good_points])\n",
        "            H, status = cv2.findHomography(image2_kp, image1_kp, cv2.RANSAC,5.0)\n",
        "        return H\n",
        "\n",
        "    def create_mask(self,img1,img2,version):\n",
        "        height_img1 = img1.shape[0]\n",
        "        width_img1 = img1.shape[1]\n",
        "        width_img2 = img2.shape[1]\n",
        "        height_panorama = height_img1\n",
        "        width_panorama = width_img1 +width_img2\n",
        "        offset = int(self.smoothing_window_size / 2)\n",
        "        barrier = img1.shape[1] - int(self.smoothing_window_size / 2)\n",
        "        mask = np.zeros((height_panorama, width_panorama))\n",
        "        if version== 'left_image':\n",
        "            mask[:, barrier - offset:barrier + offset ] = np.tile(np.linspace(1, 0, 2 * offset ).T, (height_panorama, 1))\n",
        "            mask[:, :barrier - offset] = 1\n",
        "        else:\n",
        "            mask[:, barrier - offset :barrier + offset ] = np.tile(np.linspace(0, 1, 2 * offset ).T, (height_panorama, 1))\n",
        "            mask[:, barrier + offset:] = 1\n",
        "        return cv2.merge([mask, mask, mask])\n",
        "\n",
        "    def blending(self,img1,img2):\n",
        "        H = self.registration(img1,img2)\n",
        "        height_img1 = img1.shape[0]\n",
        "        width_img1 = img1.shape[1]\n",
        "        width_img2 = img2.shape[1]\n",
        "        height_panorama = height_img1\n",
        "        width_panorama = width_img1 +width_img2\n",
        "\n",
        "        panorama1 = np.zeros((height_panorama, width_panorama, 3))\n",
        "        mask1 = self.create_mask(img1,img2,version='left_image')\n",
        "        panorama1[0:img1.shape[0], 0:img1.shape[1], :] = img1\n",
        "        panorama1 *= mask1\n",
        "        mask2 = self.create_mask(img1,img2,version='right_image')\n",
        "        panorama2 = cv2.warpPerspective(img2, H, (width_panorama, height_panorama))*mask2\n",
        "        result=panorama1+panorama2\n",
        "\n",
        "        rows, cols = np.where(result[:, :, 0] != 0)\n",
        "        min_row, max_row = min(rows), max(rows) + 1\n",
        "        min_col, max_col = min(cols), max(cols) + 1\n",
        "        final_result = result[min_row:max_row, min_col:max_col, :]\n",
        "        return final_result\n",
        "def main(argv1,argv2):\n",
        "    img1 = cv2.imread(argv1)\n",
        "    img2 = cv2.imread(argv2)\n",
        "    final=Image_Stitching().blending(img1,img2)\n",
        "    cv2.imwrite('panorama.jpg', final)\n",
        "if __name__ == '__main__':\n",
        "    try: \n",
        "        main(sys.argv[1],sys.argv[2])\n",
        "    except IndexError:\n",
        "        print (\"Please input two source images: \")\n",
        "        print (\"For example: python Image_Stitching.py '/content/WhatsApp Image 2023-01-24 at 1.52.09 AM.jpeg' '/content/WhatsApp Image 2023-01-24 at 1.52.03 AM.jpeg'\")\n",
        "    "
      ]
    }
  ]
}